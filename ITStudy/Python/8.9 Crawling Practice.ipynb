{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "list_url = \"http://eungdapso.seoul.go.kr/Shr/Shr01/Shr01_lis.jsp\"\n",
    "detail_url = \"http://eungdapso.seoul.go.kr/Shr/Shr01/Shr01_vie.jsp\"\n",
    "\n",
    "def get_save_path() :\n",
    "    save_path = str(input(\"저장할 위치와 파일명을 적어주세요 : \"))\n",
    "    save_path = save_path.replace(\"\\\\\", \"/\")\n",
    "    \n",
    "    return save_path\n",
    "    \n",
    "def fetch_list_url() :\n",
    "    request_header = urllib.parse.urlencode({\"page\" : \"1\"})\n",
    "    request_header = request_header.encode(\"utf-8\")\n",
    "    url = urllib.request.Request(list_url, request_header)\n",
    "    res = urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "    \n",
    "    bs = BeautifulSoup(res, \"html.parser\")\n",
    "    listbox = bs.find_all(\"ul\", class_=\"pclist_list2\")\n",
    "    params = []\n",
    "    for i in listbox:\n",
    "        params.append(re.search(\"[0-9]{14}\", i.find(\"a\")[\"href\"]).group())\n",
    "    \n",
    "    return params\n",
    "\n",
    "def fetch_detail_url() :\n",
    "    params = fetch_list_url()\n",
    "    \n",
    "    f = open(get_save_path(), 'w', encoding=\"utf-8\")\n",
    "    \n",
    "    for p in params :\n",
    "        request_header = urllib.parse.urlencode({\"RCEPT_NO\" : str(p)})\n",
    "        request_header = request_header.encode(\"utf-8\")\n",
    "        \n",
    "        url = urllib.request.Request(detail_url, request_header)\n",
    "        res = urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "        \n",
    "        bs = BeautifulSoup(res, \"html.parser\")\n",
    "        div = bs.find(\"div\", class_=\"form_table\")  # 속성값을 줄 때 _를 붙이는게 약속 (페이지에 따라서 class =\"\" 으로만 쓰면 안되는 경우가 있음)\n",
    "        \n",
    "        tables = div.find_all(\"table\")\n",
    "        \n",
    "        info = tables[0].find_all(\"td\")\n",
    "        title = info[0].get_text(strip=True)   # get_text(strip=True) => 공백 제거\n",
    "        date = info[1].get_text(strip=True)\n",
    "        \n",
    "        question =tables[1].find(\"div\", class_=\"table_inner_desc\").get_text(strip=True)\n",
    "        answer = tables[2].find(\"div\", class_=\"table_inner_desc\").get_text(strip=True)\n",
    "        \n",
    "        f.write(\"==\"* 30 + \"\\n\")\n",
    "        f.write(title + \"\\n\")\n",
    "        f.write(question + \"\\n\")\n",
    "        f.write(answer + \"\\n\")\n",
    "        \n",
    "        f.write(\"==\" * 30 + \"\\n\")\n",
    "        \n",
    "#fetch_list_url()\n",
    "fetch_detail_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(주석 설명)\n",
    "#서울시 응답소 페이지 크롤링 (post방식. 정부사이트같은 경우. header를 바꿔서 파악해야함)\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "\n",
    "list_url = \"http://eungdapso.seoul.go.kr/Shr/Shr01/Shr01_lis.jsp\"\n",
    "detail_url=\"http://eungdapso.seoul.go.kr/Shr/Shr01/Shr01_vie.jsp\"\n",
    "\n",
    "def get_save_path(): #패스를 저장해주는 함수 \n",
    "    save_path=str(input(\"저장할 위치와 파일명을 적어주세요 . :\"))\n",
    "    #저장할 위치와 파일명 적기\n",
    "    scve_path=save_path.replace(\"\\\\\",\"/\")\n",
    "    #/이게 있을경우 파이썬 에서 쓰는 \\\\ 의 형태로 만들어서 경로를 지정해준다.\n",
    "    \n",
    "    if not os.path.isdir(os.path.split(save_path)[0]):\n",
    "        #만약 이폴더가 없을경우 새로 생성\n",
    "        os.mkdir(os.path.split(save_path)[0])\n",
    "\n",
    "    return save_path\n",
    "#save_path를 반환\n",
    "\n",
    "def fetch_list_url():\n",
    "    #처음 리스트에서 찾는 것 \n",
    "    \n",
    "    request_header=urllib.parse.urlencode({\"page\":\"1\"})\n",
    "    #페이지를 지정해준다 1-? 사이로 넣을수 있다\n",
    "    \n",
    "    request_header=request_header.encode(\"utf-8\")\n",
    "    #이 페이지를 넣은것을 utf-8 형태로 만들어서 한글을 볼 수 있게한다.\n",
    "    \n",
    "    url=urllib.request.Request(list_url,request_header)\n",
    "    #맨위에 넣은 list_url과 헤더 값을 주고 urllib의 기능을 쓰고 그 값을 url에 저장한다.\n",
    "    \n",
    "    res=urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "    #이거 또한 utf-8의 형태로 만들고 읽고 url을 통해 오픈하고 무언가를 요청한다.\n",
    "\n",
    "    bs=BeautifulSoup(res,\"html.parser\")\n",
    "    #res에 담겨있는 내용을 html.parser를 해서 내용을 긁는다 \n",
    "    listbox=bs.find_all(\"ul\",class_=\"pclist_list2\")\n",
    "    #parser한 내용 =bs 를 find.all로 내가 원하는 부분을 찾는데\n",
    "    #그 부분은 ul에 있고 그 속에 class중 pclist 라는 곳에 있다 이 부분을\n",
    "    # listbox 에 넣는다\n",
    "    \n",
    "    #class_= 는  ui 에 대한 속성이라고 말해주는 것\n",
    "    #해줘도 되고 안해도 되는데 안하면 오류날수도 있어서 해주는게 좋다\n",
    "    params=[]\n",
    "    #배열 하나 만들고 \n",
    "    for i in listbox:\n",
    "        params.append(re.search(\"[0-9]{14}\",i.find(\"a\")[\"href\"]).group())\n",
    "    #for문을 돌려서 listbox 의 양 만큼 돌리는데 이때 search를 하고 그 search는\n",
    "    #숫자 0-9까지의 숫자중에 14자리의 숫자를 가져오는데 이 때\n",
    "    #i.find로 0~listbox의 갯수 만큼 돌리고 i 에서 href의 a 라는 부분을 가져와서\n",
    "    #아까만든 params라는 배열에 append로 하나씩 넣어준다. \n",
    "    return params\n",
    "    #그다음 return으로 넣어준다.\n",
    "\n",
    "def fetch_detail_url():\n",
    "    #이건 자세한 url부분이다.\n",
    "    params=fetch_list_url()\n",
    "    #위에서 한 값을 받아오기 위해 변수를 하나 선언해서 저장하고\n",
    "    \n",
    "    f=open(get_save_path(),'w',encoding=\"utf-8\")\n",
    "    #우리가 파일을 하나 저장해주기 위해 위에 get_save_path()를 쓰고 여기에\n",
    "    #w를 써서 파일을 새로 저장해준다 이때도 utf-8형식으로 만든다. \n",
    "\n",
    "    for p in params:\n",
    "    # p는 i 와 같은 효과를 하고 여기서 위에서 가져온 처음 기본페이지에서 가져온\n",
    "    #숫자값을 배열에 넣은 params를 길이 만큼 돌리기 위한 for문이다 \n",
    "        request_header = urllib.parse.urlencode({\"RCEPT_NO\":str(p)})\n",
    "    #여기서 헤더를 만들어주는데 헤더부분은 \"RCEPT_NO\": ???? 이 물음표는\n",
    "    #전 페이지에서 하나의 게시글 마다 가지고 있는 고유한 번호를 넣어서 가져오고\n",
    "    #이 값을 헤더로 넣어주는 방식인것 같다 \n",
    "    \n",
    "        \n",
    "    #헤더는 문자열로 받아야 인식을 한다. 이번호를 고유 번호로 인식하고 해당 페이지를 요청한다\n",
    "        request_header=request_header.encode(\"utf-8\")\n",
    "        #이또한 utf-8\n",
    "\n",
    "        url=urllib.request.Request(detail_url,request_header)\n",
    "        #detail_url을 header와 같이 넣어서 요청해준다.\n",
    "        \n",
    "        res=urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "        #이또한 utf-8로 새로한다 이거 하는 이유는 한글 안깨지게 하기위해\n",
    "\n",
    "        bs=BeautifulSoup(res,\"html.parser\")\n",
    "        #아까와 동일 ( 아마해당 페이지의 전체 html 소스를 가져오는 것 같다.\n",
    "        div=bs.find(\"div\",class_=\"form_table\")\n",
    "        #find를 하는데 div중 에 class이름이 form_table이라는 것을 찾아 저장한다.\n",
    "\n",
    "        tables=div.find_all(\"table\")\n",
    "        #find_all 로 전체에서 table이라는 것을 가져온다\n",
    "        info=tables[0].find_all(\"td\")\n",
    "        #이건 첫번째 테이블로 테이블에서 td라는 부분을 가져온다 \n",
    "\n",
    "        title=info[0].get_text(strip=True)\n",
    "        #info가 배열로 되는 이유는 tables가 여러개 여서 그렇고\n",
    "        #이 0번째 테이블에서는 td가 두개다 그래서 info의 배열이 두개가 나오고\n",
    "        #그 두가지의 의미가 하나는 title이고 하나는 date이다\n",
    "        #그 해당 하는 값에 대해 .get_text(strip=True) 를 써서 공백을 없애준다.\n",
    "        date=info[1].get_text(strip=True)\n",
    "\n",
    "        question=tables[1].find(\"div\",class_=\"table_inner_desc\").get_text(strip=True)\n",
    "        #그 테이블에서 또 find를 해서 해당하는 부분가져오고 그 부분에서 공백을 제거한 값을 넣어준다.\n",
    "        answer=tables[2].find(\"div\",class_=\"table_inner_desc\").get_text(strip=True)\n",
    "\n",
    "        #이제 우리가 찾은 값을 하나씩써준다. \n",
    "        f.write(\"==\" * 30+ \"\\n\")\n",
    "\n",
    "        f.write(title+ \"\\n\")\n",
    "        f.write(date+ \"\\n\")\n",
    "        f.write(question+ \"\\n\")\n",
    "        f.write(answer+ \"\\n\")\n",
    "\n",
    "        f.write(\"==\" * 30+ \"\\n\")\n",
    "        #끄읏\n",
    "fetch_detail_url()\n",
    "#프로그램 실행 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from itertools import count\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_request_url(url, enc='utf-8'):\n",
    "    \n",
    "    req = urllib.request.Request(url)\n",
    "    \n",
    "    try: #페이지가 안넘어오는 것에 대한 예외처리. 여기서는 get방식으로 정보를 얻어온다\n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() ==200: #새로운 매장이 생겼을 경우, 해당되는 새 페이지가 있으면 200이라는 응답이 올 것이기 때문에 확인.\n",
    "                                     #404라면 해당 페이지가 없는 것.\n",
    "            \n",
    "            try:\n",
    "                rcv = response.read()\n",
    "                ret = rcv.decode(enc)\n",
    "            except UnicodeDecodeError:\n",
    "                ret = rcv.decode(enc, 'replace')\n",
    "            return ret\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL : %s\" % (datetime.datetime.now(), url))\n",
    "        return None\n",
    "    \n",
    "def getPelicanaAddress(result):\n",
    "    \n",
    "    for page_idx in count(): #itertools의 count() (숫자를 무한대로 발생시켜줌 - 무한루프). \n",
    "        \n",
    "        Pelicana_URL = 'http://www.pelicana.co.kr/store/stroe_search.html?=&page=%s' % str(page_idx +1) #0부터 루프가 돌기떄문에 +1\n",
    "        print(\"[Pericana Page] : [%s]\" % (str(page_idx +1)))\n",
    "        \n",
    "        rcv_data = get_request_url(Pelicana_URL) # 200번 응답 받을 때까지 돌린다.\n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "        \n",
    "        store_table = soupData.find('table', attrs={'class':'mt20'})\n",
    "        # \n",
    "        tbody = store_table.find('tbody')\n",
    "        bEnd = True\n",
    "        for store_tr in tbody.findAll('tr'):\n",
    "            bEnd = False\n",
    "            tr_tag = list(store_tr.strings)\n",
    "            store_name = tr_tag[1]\n",
    "            store_address = tr_tag[3]\n",
    "            store_sido_gu = store_address.split()[:2]\n",
    "            \n",
    "            result.append([store_name] + store_sido_gu+[store_address])\n",
    "            \n",
    "        if(bEnd == True) :\n",
    "            return\n",
    "    return\n",
    "\n",
    "def main():\n",
    "    result = []\n",
    "    \n",
    "    print('PERICANA ADDRESS CRAWLING START')\n",
    "    getPelicanaAddress(result)\n",
    "    print(result)\n",
    "    pericana_table = pd.DataFrame(result, columns=('store', 'sido', 'gungu', 'store_address'))\n",
    "    pericana_table.to_csv(\"C:\\ITStudy\\Python\\pericana.csv\", encoding=\"cp949\", mode='w', index=True)\n",
    "    del result[:]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Review Page] : [1]\n",
      "[Review Page] : [2]\n",
      "[Review Page] : [3]\n",
      "[Review Page] : [4]\n",
      "[Review Page] : [5]\n",
      "[Review Page] : [6]\n",
      "[Review Page] : [7]\n",
      "[Review Page] : [8]\n",
      "[Review Page] : [9]\n",
      "[Review Page] : [10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': '10', 'review': '공감누르면 7편때 애인이랑 볼수잇음  '},\n",
       " {'score': '10', 'review': '톰 크루즈가 30년째 톱스타인 이유  '},\n",
       " {'score': '10', 'review': '인랑 따위랑 비교가안돼  '},\n",
       " {'score': '10', 'review': '시사회에서 봤는데 난 이쯤되면 톰 크루즈의 한계는 진짜 어디까진지 궁금하다.  '},\n",
       " {'score': '10',\n",
       "  'review': '탐 크루즈가 고생하는거보니 막판엔 눈물 나올라했음. 영화비 8천원에 이렇게 보는게 미안할정도. 나 나이 먹는거보다 탐 크루즈가 나이먹는게 더 싫음. 미션임파서블 오래오래 보고싶어서. 분명 미션 클리어할거 아는데도 심장 쫄깃해지는 최고의 영화~~~~  '},\n",
       " {'score': '10', 'review': '박평식형님이 7점줬다 믿고보자  '},\n",
       " {'score': '10',\n",
       "  'review': '이영화는 진짜다. 아무리 평점을 깍아내리려고해도 인간인 이상 양심을 속여 깍아내릴 수는없다. 만약 깍아내린다면 그건 진짜 싸이코패스다.  '},\n",
       " {'score': '10',\n",
       "  'review': '미션임파서블 앞 시리즈 하나도 안봤는데 이해할수있나요? ㅠ ㅠ 보는걸추천하면 공감, 앞 시리즈 모르면 반대 비공감 해주세요.. ㅠㅠ  '},\n",
       " {'score': '9',\n",
       "  'review': '야 니들 이런 헐리웃대작과 한국영화가 같은 관람료인게 정상이라고 생각하냐? 한국영화는 그냥 4000원이 적당하다.  '},\n",
       " {'score': '10', 'review': '이영화가 인랑보다 괜객이 적으면 말이되나  '},\n",
       " {'score': '10',\n",
       "  'review': '아니 도대체 이 형님은 못하는게 뭐야~ 암벽등반은 기본이고 하다하다 헬기조종씬까지ㅋ 시원시원하이 최고였음~ 만수무강하시고 칠순까지 미션10 갑시다!!!ㅋ  '},\n",
       " {'score': '10',\n",
       "  'review': '헬기 조정도 직접하고 초반에 프랑스 상공 위에서 떨어지는 장면도 직접 했다네요. 대스타 이름값 합니다. 영화를 보시면 탐크루즈가 존경스럽기까지 합니다.  '},\n",
       " {'score': '10', 'review': '시사회로 봤다. 무더위에 시원시원한 액션보고 싶으면 최고라고 생각한다.  '},\n",
       " {'score': '9',\n",
       "  'review': 'CG가 판치는 영화계에 이 얼마나 신선한 아날로그적인 액션인가.늙어가는 톰 크루즈 보다 임파서블 씨리즈를 못 할까봐 걱정이 된다.  '},\n",
       " {'score': '10', 'review': '이 시리즈에서 만큼은 영화가 감독의 예술이 아니다.  '},\n",
       " {'score': '10', 'review': '시리즈의 최고작이다.  '},\n",
       " {'score': '10', 'review': '최고의 액션, 노 스턴트, 시원하고 짜릿하다. 월타 gv로 봤고 강추합니다  '},\n",
       " {'score': '10', 'review': '역시 이 영화는 끝날때까지 끝난게 아니죠.  '},\n",
       " {'score': '10', 'review': '음악만으로도 설렌다...빰빰 빰빠 빰빠  빰빰빠~~~~♡♡♡♡  '},\n",
       " {'score': '10', 'review': '올해 본 영화중 최고네요  '},\n",
       " {'score': '10',\n",
       "  'review': '톰형의 시원한 액션 정말 맘에들고 강추합니다평점 짜게 주기로 유명한 평식이형이 7점이나 준 이유가 다 있네요  '},\n",
       " {'score': '10', 'review': '형... 미안한데 7편도 내줘야겠어요  '},\n",
       " {'score': '10', 'review': '방금보고나왔는데 아 대박 진짜 역대급 말이 안나온다 이건 극장에서 안보면 미친거다  '},\n",
       " {'score': '10', 'review': '헨리형 dc에서 애먹다가 이쪽에서오니 보기좋네♡  '},\n",
       " {'score': '10', 'review': '역시 톰크루즈다.말해서 뭐하나...  '},\n",
       " {'score': '10',\n",
       "  'review': '현존 시리즈 당연 최고봉! 톰, 헨리 둘 다 너무 멋있었는데, 헨리는 그냥 미쳤다.. 카리스마가 흘러 넘쳐..  '},\n",
       " {'score': '10', 'review': '하도 입벌리고 봐서 입이 다 마름  '},\n",
       " {'score': '10',\n",
       "  'review': '시리즈중 최고걸작임  액션 스토리 서스펜스 메시지 빠지는거없이 완벽하게만듬 특히 크루즈형 cg없는액션시퀀스압권  '},\n",
       " {'score': '10', 'review': '톰형의 한계는 도대체 어디까지인지 궁금하다.  '},\n",
       " {'score': '10', 'review': '역대 최강 미션임파서블 시리즈중걸작입니다 인랑보시려면 이걸 보세요!!  '},\n",
       " {'score': '10', 'review': '톰 트루즈를 갈아서 만든 영화.  '},\n",
       " {'score': '10', 'review': '이게  바로 액션영화지  화장실 격투신 ㄷㄷ  '},\n",
       " {'score': '10', 'review': '톰형님 영원히 안늙었으면 좋겠다 ..  '},\n",
       " {'score': '10',\n",
       "  'review': '최고였다. 두시간 반이 시간가는줄 모르고 지나갔음. 액션씬도 멋있었고, 게다가 스턴트/CG없이 맨몸액션이라는게 놀랍고, 광활한 자연을 배경으로 한 액션씬도 대박이었고, 스토리 구성도 좋았음. 배우들의 케미도 좋았고, 하나하나 매력적인 캐릭터들이었고.  '},\n",
       " {'score': '10', 'review': '톰형 싸랑해요 지금 보러갑니다  '},\n",
       " {'score': '10', 'review': '마지막 장면은 알고도 숨 죽일수 밖에 없다.  '},\n",
       " {'score': '10', 'review': '국산영화에서 절대볼수없는 스케일과 CG에 감탄할 따름입니다.  '},\n",
       " {'score': '10',\n",
       "  'review': '진짜 긴장감 몰입도 역대급;; 전작들 다 씹어먹음 ㅋㅋㅋ 반전 있을거 알면서도 보는데도 긴장감넘치고 반전 그이상의 뭔가가 더 있음ㅋㅋㅋ 개쩜 그냥 개쩜 세번보셈 꼭  '},\n",
       " {'score': '10',\n",
       "  'review': '진심 내가 공중에 매달린것 같고 내가 공중에 떠있는 것 같고 내가 암벽등반하는 것 같고 내가 드라이브 하는것 같음....소리랑 연출이 진짜 장난없이 좋음 스토리는 10점 만점임  '},\n",
       " {'score': '10', 'review': '톰형 달리기 장면 ㄷㄷ 62년생 ㄷㄷ...  '},\n",
       " {'score': '9', 'review': '톰형은 언제나 끝까지 간다!  '},\n",
       " {'score': '10', 'review': '톰형 도대체 얼마나 뛴거야ㄷㄷㄷ  '},\n",
       " {'score': '10',\n",
       "  'review': '안본 눈 삽니다ㅠㅠ 기억리셋해서 다시보고싶을 정도네요@@@ 처음부터 끝까지 긴장감을 놓치지 않았습니다 시리즈 중에서도 완전 최고!!! 제발 아무도 안본사람 없게해주세요 ㅠㅠㅠㅠ  '},\n",
       " {'score': '10',\n",
       "  'review': '그냥 잔말말고 보세요. 역대급입니다 . 이게 액션입니다. 다른영화 액션이라고 이름붙이지 마세요  '},\n",
       " {'score': '10', 'review': '아니 나 잔짜로 10점 만점에 천만점이야  '},\n",
       " {'score': '8',\n",
       "  'review': '다시금 곱씹게 된 에단 헌트의 사랑, 리얼 액션으로 빚어낸 헬기 클라이맥스에 집중할 것. 3,4,5편을 보고 감상하면 더 좋습니다.  '},\n",
       " {'score': '10', 'review': '톰형의 클라쓰는 어딜가지않네ㄷㄷ  '},\n",
       " {'score': '8', 'review': '노스턴트로 촬영했다는걸 알고보니 훨씬 더 몰입되고 긴장된다  '},\n",
       " {'score': '10',\n",
       "  'review': 'CG 덕지발라놓은 마블 보면서 이제 지루해서 잠드는 내가 크루즈 형의 액션은 여전했고 더위를 충분히 잠재울만 했다!!  '},\n",
       " {'score': '9', 'review': '나도 점수 박하게 주는 편인데.내용도 좋았지만,톰형 액션에 감탄을 안할 수가 없더라.  '},\n",
       " {'score': '10', 'review': '뻔한걸 잘하는게 실력이다.  '},\n",
       " {'score': '10', 'review': '톰 횽아 드디어 인생영화 찍으심 끼요오오옷  '},\n",
       " {'score': '10', 'review': '오토바이 씬 대박)!!  '},\n",
       " {'score': '10', 'review': '인간적으로 이런 영화는 12000원받고인랑같은 영화는 6000원만 받자  '},\n",
       " {'score': '10', 'review': '이번 시리즈는 정말 잘만든듯.. 인정할건 인정함.  '},\n",
       " {'score': '10', 'review': '그냥 10점주고 보러감  '},\n",
       " {'score': '10', 'review': '방금보고 나왔는대  최고입니다 볼만합니다  '},\n",
       " {'score': '10', 'review': '톰 크루즈의 액션은 언제나 옳다. 봐도봐도 질리지가 않는 시원한 액션.  '},\n",
       " {'score': '10',\n",
       "  'review': '저는 손에 땀을 쥐며 본다는게 어떤건지 알겠습니다 비슷한 영화들이 많은데 클리쉐를 느끼게 하는 장면이 없었어요 고심하며 찍은듯 합니다 스토리는 좀 약하고 예상가능하나 그 모든걸 액션으로 만회합니다 7탄 기대하고 기다립니다  '},\n",
       " {'score': '10', 'review': '톰이  전력질주하는 모습을 보는 자체가 제일 경이롭다  '},\n",
       " {'score': '10', 'review': '이게 영화다 그저 갓갓ㄷㄷ  '},\n",
       " {'score': '10',\n",
       "  'review': '영화 본 사람들은 메이킹필름도 함 보시길... 헬기씬 전부 톰이 직접 헬기 조종 배워서 조종하고, 연기하는 동시에 본인 찍고 있는 카메라 조정까지 다하는 리얼.. 낙하씬도 노CG.. 건물 뛰는 장면도 노CG...(전부 예고에 나온 장면입니다. 노스포)  '},\n",
       " {'score': '10', 'review': '톰크루즈 연봉받는이유있다  '},\n",
       " {'score': '10',\n",
       "  'review': '이 형 내일모레 환갑인데 미안하지만 8편까지는 찍고 바통터치하자. 첩보액션물에선 진짜 독보적이다.  '},\n",
       " {'score': '10',\n",
       "  'review': '최근 3년안에 본 외화중 가장 훌륭한 액션외화네 압도적이다.2시간 20분이 어떻게 간지도 모르겠다  '},\n",
       " {'score': '10',\n",
       "  'review': '톰형이 진짜 목숨 걸고 찍은 무보정 액션에 경이로움을 느낌. 나이를 먹는 모습에 짠하긴 함.개연성 충만한 스토리와 배우들의 장인급 연기에, 뭣보다 다을듯말듯한 서프라이즈 로맨스(?)까지...현존 액션 영화 시리즈 가운데 단연 No.1~~^^  '},\n",
       " {'score': '10', 'review': '얼만큼 위험했어? 평소같았어 ㅋ  '},\n",
       " {'score': '10', 'review': '4Dx보고왔는데  너무 재미있게 보고왔어요  '},\n",
       " {'score': '10', 'review': '성룡 톰크루즈 이둘의액션을 지켜본시대의나는 행운아  '},\n",
       " {'score': '10',\n",
       "  'review': 'ㅋㅋㅋ런닝맨에서 톰크루즈가 미스터리박스에 손 집어넣을때 하나도 안무섭다고 하더니 이유가 있었네요. 영화가 훨씬 더무서움; 특히 마지막 헬기씬..  '},\n",
       " {'score': '10',\n",
       "  'review': \"탐크루즈만 믿고 봤는데, 감독의 필모그래피를 보니 장난이 아니다. 크리스토퍼 맥쿼리 감복이 각본을 맡은영화 : 미이라, 엣지오브투모로우, 더울버린, 잭리처, 작정명발키리 그리고 무려 '유주얼 서스펙트' ㄷㄷㄷ  \"},\n",
       " {'score': '10', 'review': '저는 최고라고 생각합니다. 물론 1편이 가장 좋았다고도 하지만 전 최고였습니다.  '},\n",
       " {'score': '9',\n",
       "  'review': '톰형님 액션연기만 봐도 만족인데 다른 배우들 연기와 화려한 볼거리들이 넘침.근데 여기서 끝이 아니고 시리즈를 정리하는듯한 마무리까지 이거 안보면 후회함  '},\n",
       " {'score': '10', 'review': '함부로 리얼액션 하지말길...이게 리얼이지 리얼  '},\n",
       " {'score': '9', 'review': '믿는 도끼에 발등 찍히지 않아 좋습니다  '},\n",
       " {'score': '10', 'review': '헬기 씬이 진짜 리얼했다  '},\n",
       " {'score': '10', 'review': '시리즈중에 제일 재밌었음. 스케일 장난아니고 손에 담쥐는 30분같은 15분이었음ㅎ  '},\n",
       " {'score': '9',\n",
       "  'review': '강렬한 인트로, 가슴뛰는 BGM, 미친 스턴트액션..우리가 미션임파서블이라는 프랜차이즈에 바라는 모든 것의 집대성임 2015년에 매드맥스 분노의 도로가 있었다면 20OOO에는 미션임파서블 폴아웃이 있음 특히 마지막 전투씬에선 말그대로 손에 땀을 쥠  '},\n",
       " {'score': '9', 'review': '6편 조차도 이리 대단한가, 다른 시리즈 영화는 엄두도 못내는 6편을  '},\n",
       " {'score': '10', 'review': '돈을 더 지불하고 싶었다. 미쳤다.  '},\n",
       " {'score': '10', 'review': '이걸 영화관에서 본건 최고의 선택이었다.  '},\n",
       " {'score': '10', 'review': '최고다 아싸 아싸아싸아싸  '},\n",
       " {'score': '8',\n",
       "  'review': '자고로 액션영화의 시리즈물은 이래야 된다는 걸 보여줬다.. 톰형은 늙지도 않는다..그리고 더 빨라진 거 같다..  '},\n",
       " {'score': '10',\n",
       "  'review': '헬기 씬이 와~~ 아이맥스로 보세요 로튼 토마토 점수가 괜히 나온게 아님. 대역이 없으니 배우놓고 그대로 찍는데 사실감 장난 아닙니다. 기존 헬리콥터 액션 다 처바름.  '},\n",
       " {'score': '8', 'review': '정강이 부러지는거 편집안했네요 알고봐서 다리 꺽이는거 보이니 ㅎ ㄷ ㄷ  하네요 ㅠㅠ  '},\n",
       " {'score': '10',\n",
       "  'review': 'cg가 아닌 탐크루즈의 실제 연기가 극도의 몰입으로 이끌어 준다.. 전설로 길이 남을 영화  '},\n",
       " {'score': '10', 'review': '미션임파서블의 톰아저씨는 늘 기대에 부응함  '},\n",
       " {'score': '10',\n",
       "  'review': '항상 큰기대를 저버리지않는 시리즈.심지어 이번엔 그 기대를 넘어서네.영화 참 오지게봐왔지만  이렇게 소름  많이돋는 영화는 첨일세.톰형 수고했어요.돈많이 버세요.환갑까지 씨리즈 몰고가봅시다.  '},\n",
       " {'score': '10',\n",
       "  'review': '오랜만에 극장에서 엄지척 내밀었다!돈 만원도 오히려 미안한 영화역시 믿고 보는 톰 형 ~사랑해요 톰 크루즈 ~  '},\n",
       " {'score': '9', 'review': '믿고보는 톰크루즈 나이먹어도 여전히멋있네요  '},\n",
       " {'score': '10', 'review': '처음에 빰빰빠 나왔을때 소름  '},\n",
       " {'score': '10', 'review': '액션영화보다 운건 처음이네요  '},\n",
       " {'score': '8',\n",
       "  'review': '요즘 점점 한국영화와 외국영화의 차이가 극명하게 드러난다...돈만,외모만,천만관객만 바라는 한국영화계는 반성해야 한다.  '},\n",
       " {'score': '10',\n",
       "  'review': '시리즈물의 교본이라고 하자... 존잼이고 일단 존멋이고..ㅠㅠ 테마곡 나오자마자 전율 크으으으 시리즈 정주행하고 보면 더 이해 잘됨 벗 그냥 봐도 무방. 올여름 익스트림 액션 끝판왕. 꼭 극장가서 보길!!!  '},\n",
       " {'score': '10', 'review': '와. 다음시리즈 만들어주세요. 톰크루즈 나이먹는게 왤케 시르냐 ㅠㅠ  '},\n",
       " {'score': '10', 'review': '돈주고 볼만한 가치가 았는 영화  '},\n",
       " {'score': '10',\n",
       "  'review': '잘 자리잡은 시리즈, 배우들 전부 본인한테 꼭 맞는 옷을 입은듯 캐릭터에 잘 묻어냈다그 중에서도 톰 크루즈의 노련미는 단연 돋보임!!  '},\n",
       " {'score': '8', 'review': '역시 믿고보는 배우네요~너무 재밌게 봤어요  '},\n",
       " {'score': '10', 'review': '탐 형님 달리는 모습에 정말 감탄을 안할수가 없습니다존경 스럽습니다  '},\n",
       " {'score': '10',\n",
       "  'review': '미션시리즈 답게 톰형의 몸서리지않는 액션..박수쳐주고 싶다 ㅎㅎ이더운 여름을 식혀줄 영화 다음시리즈도 기대하겟습니다  '}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#네이버 영화 평점 크롤러\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from itertools import count\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_request_url(url, enc='utf-8'):\n",
    "    \n",
    "    req = urllib.request.Request(url)\n",
    "    \n",
    "    try: #페이지가 안넘어오는 것에 대한 예외처리. 여기서는 get방식으로 정보를 얻어온다\n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() ==200: #새로운 페이지\n",
    "            try:\n",
    "                rcv = response.read()\n",
    "                ret = rcv.decode(enc)\n",
    "            except UnicodeDecodeError:\n",
    "                ret = rcv.decode(enc, 'replace')\n",
    "            return ret\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL : %s\" % (datetime.datetime.now(), url))\n",
    "        return None\n",
    "    \n",
    "def getMovieReview(): #영화 리뷰 불러오는 함수 생성\n",
    "    result = {} #딕셔너리\n",
    "    result_list = [] #리스트\n",
    "    \n",
    "    for page_idx in range(0,10): #편의를 위해 10페이지까지만. \n",
    "        \n",
    "        Review_URL = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=154222&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=%s' % str(page_idx +1) #0부터 루프가 돌기떄문에 +1\n",
    "        \n",
    "        \n",
    "        print(\"[Review Page] : [%s]\" % (str(page_idx +1)))\n",
    "        \n",
    "        rcv_data = get_request_url(Review_URL) # 200번 응답 받을 때까지 돌린다.\n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "        \n",
    "        score_result = soupData.find('div', class_='score_result').find('ul')\n",
    "        lis = score_result.find_all('li')\n",
    "        \n",
    "        for li in lis:\n",
    "            score = li.find('div', class_='star_score').find('em').get_text()\n",
    "            spectator = li.find('div', class_='score_reple').find('span').get_text()\n",
    "            review = li.find('div', class_='score_reple').find('p').get_text()\n",
    "            #별점, 관람객인지 여부, 리뷰내용에 대한 text 불러오기\n",
    "            \n",
    "            if spectator == '관람객': #관람객인지 여부 확인\n",
    "                review = review[3:] #관람객에 대한 문자 제거\n",
    "            \n",
    "            result['score'] = score\n",
    "            result['review'] = review\n",
    "            \n",
    "            result_list.append({\n",
    "                'score' : score,\n",
    "                'review' : review\n",
    "            })\n",
    "    return result_list\n",
    "    print('NAVER MOVIE REVIEW CRAWLING START')\n",
    "    print(result_list) #내용 출력\n",
    "    review_table = pd.DataFrame(result_list, columns=('score', 'review')) #테이블 생성 및 csv파일 생성\n",
    "    review_table.to_csv(\"C:\\ITStudy\\Python\\moviereview.csv\", encoding=\"cp949\", mode='w', index=True)\n",
    "\n",
    "getMovieReview() #실행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url을 입력하세요: http://movie.naver.com/movie/bi/mi/point.nhn?code=121788\n",
      "input save path: C:\\ITStudy\\Python\\reviewtest.txt\n",
      "게시물의 검색 개수를 입력하세요(10단위): 100\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=1\n",
      "10초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=2\n",
      "8초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=3\n",
      "8초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=4\n",
      "6초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=5\n",
      "5초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=6\n",
      "7초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=7\n",
      "10초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=8\n",
      "5초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=9\n",
      "7초 기다렸습니다.\n",
      "http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=10\n"
     ]
    }
   ],
   "source": [
    "#네이버 영화 평점 크롤러 선생님 답안\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "#http://movie.naver.com/movie/bi/mi/point.nhn?code=121788\n",
    "\n",
    "url1 = 'http://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code='\n",
    "url2 = '&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page='\n",
    "hdr = {\n",
    "    'User-Agent' : 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36',\n",
    "    'Host' : 'movie.naver.com',\n",
    "    'Connection' : 'keep-alive',\n",
    "    'referer' : 'http://m.naver.com'\n",
    "}\n",
    "\n",
    "def split_url():\n",
    "    url = input('url을 입력하세요: ')\n",
    "    code_str = re.search('code=[0-9]*', url).group()\n",
    "    code = re.search('[0-9]+', code_str).group()\n",
    "    \n",
    "    return code\n",
    "\n",
    "def fetch_score_result(URL):\n",
    "    print(URL)\n",
    "    result = {}\n",
    "    result_list = []\n",
    "    \n",
    "    res = urllib.request.Request(URL, headers=hdr)\n",
    "    response = urllib.request.urlopen(res)\n",
    "    \n",
    "    html = response.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    score_result = soup.find('div', class_='score_result').find('ul')\n",
    "    lis = score_result.find_all('li')\n",
    "        \n",
    "    for li in lis:\n",
    "        score = li.find('div', class_='star_score').find('em').get_text()\n",
    "        spectator = li.find('div', class_='score_reple').find('span').get_text()\n",
    "        review = li.find('div', class_='score_reple').find('p').get_text()\n",
    "            #별점, 관람객인지 여부, 리뷰내용에 대한 text 불러오기\n",
    "            \n",
    "        if spectator == '관람객': #관람객인지 여부 확인\n",
    "             review = review[3:] #관람객에 대한 문자 제거\n",
    "            \n",
    "        result['score'] = score\n",
    "        result['review'] = review\n",
    "            \n",
    "        result_list.append({\n",
    "             'score' : score,\n",
    "             'review' : review\n",
    "             })\n",
    "    return result_list\n",
    "\n",
    "def input_save_path():\n",
    "    save_path = str(input(\"input save path: \"))\n",
    "    save_path = save_path.replace('\\\\', '/')\n",
    "    if not os.path.isdir(os.path.split(save_path)[0]):\n",
    "        os.mkdir(os.path.split(save_path)[0])\n",
    "    return save_path\n",
    "def fetch_reviews():\n",
    "    code = split_url()\n",
    "    f = open(input_save_path(), 'w', encoding='utf-8')\n",
    "    page = 1\n",
    "    while True:\n",
    "        count = int(input('게시물의 검색 개수를 입력하세요(10단위): '))\n",
    "        if count % 10 == 0 :\n",
    "            break\n",
    "    l_count = 1\n",
    "    isLoop = True\n",
    "    while isLoop:\n",
    "        URL = url1 + code + url2 + str(page)\n",
    "        result_list = fetch_score_result(URL)\n",
    "        \n",
    "        for r in result_list:\n",
    "            \n",
    "            f.write('==' * 40 + '\\n')\n",
    "            f.write('영화 평점: ' + r['score'] + '\\n')\n",
    "            f.write('리뷰내용: ' + r['review'] + '\\n')\n",
    "            f.write('==' * 40 + '\\n')\n",
    "            l_count += 1\n",
    "            if l_count > count:\n",
    "                isLoop = False\n",
    "                break\n",
    "        page += 1\n",
    "        if not isLoop or l_count == count:\n",
    "            isLoop = False\n",
    "            break\n",
    "        \n",
    "        sleepTime = random.randint(4,10)\n",
    "        time.sleep(sleepTime)\n",
    "        print(str(sleepTime) + '초 기다렸습니다.')\n",
    "    f.close()\n",
    "fetch_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
